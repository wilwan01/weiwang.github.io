<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Wei Wang</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Wei Wang</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Patents</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#skills">Talks</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#interests">Interests</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Services</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0">Wei
          <span class="text-primary">Wang</span>
        </h1>
        <div class="subheading mb-5">
          <a href="https://goo.gl/maps/8EbFmp8KmHoha9fQ7">Find me</a>
        </div>
        <p class="lead mb-5"> I'm a researcher at Arm Research in Cambridge, where I lead the systems research on non-volatile memories. My current research focus is on addressing the programming challenges of persistent memory, balancing programmability and performance. </p>
        <div class="social-icons">
          <a href="https://scholar.google.co.uk/citations?user=nJ9OLBoAAAAJ&hl=en&authuser=1">
            <i class="fab fa-google"></i>
          </a>
        </div>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="experience">
      <div class="w-100">
        <h2 class="mb-5">Selected Publications</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/spaa19_paper.pdf>Persistent Atomics for Implementing Durable Lock-Free Data Structures for Non-Volatile Memory</a></h3>
            <div class="subheading mb-3">Addressing NVM Programming Challenges</div>
            <p> This brief announcement presents a persist ordering problem uncovered in implementing durable lock-free data structures for non-volatile memory and proposes a hardware solution with persistent atomics in the Arm instruction set architecture.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">SPAA'19, June 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/toppicks-19.pdf>Language support for memory persistency</a></h3>
            <div class="subheading mb-3">Addressing NVM Programming Challenges</div>
            <p>Memory persistency models enable maintaining recoverable data structures in persistent memories and prior work has proposed ISA-level persistency models. In addition to these models, we argue for extending language-level memory models to provide persistence semantics. We present a taxonomy of guarantees a language-level persistency model could provide and characterize their programmability and performance.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">IEEE Micro Top Picks, May-June 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/dac19.pdf>Efficient State Retention through Paged Memory Management for Reactive Transient Computing</a></h3>
            <div class="subheading mb-3">NVM for IoT</div>
            <p>Reactive transient computing systems preserve computational progress despite frequent power failures by suspending (saving state to nonvolatile memory) when detecting a power failure, and restoring once power returns. Existing methods inefficiently save and restore all allocated memory. We propose lightweight memory management that applies the concept of paging to load pages only when needed, and save only modified pages. We then develop a model that maximises available execution time by dynamically adjusting the suspend and restore voltage thresholds. Experiments on an MSP430FR5994 microcontroller show that our method reduces state retention overheads by up to 86.9% and executes algorithms up to 5.3× faster than the state-of-the-art.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">DAC'19, June 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/nvmw19.pdf>Strand Persistency</a></h3>
            <div class="subheading mb-3">Addressing NVM Programming Challenges</div>
            <p> Strand persistency enables high persist concurrency in all designs. We compare performance achieved due to our strand implementation as compared to the baseline Coupled-SFR, DecoupledSFR, and ATLAS designs. Overall, we achieve performance improvement of up to 21.8% (14.3% avg.) in Coupled-SFR, 34.5% (21.4% avg.) in Decoupled-SFR, and 29.9% (18.2% avg.) in ATLAS with our strand implementation.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">NVMW'19, March 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/fast19.pdf>Software Wear Management for Persistent Memories</a></h3>
            <div class="subheading mb-3">Addressing NVM Endurance Challenges</div>
            <p> The commercial release of byte-addressable persistent memories (PMs) is imminent. Unfortunately, these devices suffer from limited write endurance—without any wear management, PM lifetime might be as low as 1.1 months. Existing wear-management techniques introduce an additional indirection layer to remap memory across physical frames and require hardware support to track fine-grain wear. These mechanisms incur storage overhead and increase access latency and energy consumption.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">FAST'19, Feburary 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/memsys18_paper.pdf>Quantifying the performance overheads of PMDK</a></h3>
            <div class="subheading mb-3">Addressing NVM Programming Challenges</div>
            <p> For systems with non-volatile main memories, i .e., NVDIMMs, failure atomicity is required to guarantee that systems can always recover to consistent states following power or system failures. Such failure atomicity can be achieved with logging and flushing as with filesystems. Similarly, with non-volatile main memories, failure atomicity can be achieved with user space applications using write logging, cacheline flushing, and barriers that order such operations. Write logging, either undo or redo logging, ensures atomicity when a failure interrupts the last atomic operation from completion. Undo logging helps systems recover to the last consistent state immediately before the failed atomic operation, and redo logging helps systems restore to the consistent state right after the failed atomic operation. Cacheline flushing ensures volatile caches do not hold persistent data from reaching the point of persistence, so persistent data won’t be lost when a sudden power or system failure occurs. Barriers help prevent potential reordering in the memory hierarchy, as caches and memory controllers may reorder memory operations. For example, a barrier ensures the undo log copy of the data gets persisted onto the persistent memory before the data is mutated in-place, so it’s guaranteed that the last atomic operation can be rewound should a failure happens. However, it’s non-trivial to add such failure atomicity in user applications with low-level operations such as write logging, cacheline flushing, and barriers. PMDK is a user space library that abstracts such low-level operations away from application developers and wraps such operations into transactional APIs in libpmemobj that user space applications can call for ensuring failure atomicity. This work quantifies the performance overheads of PMDK</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">MEMSYS'18, October 2018</span>
          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/pldi18.pdf>Persistency for synchronization-free regions</a></h3>
            <div class="subheading mb-3">Addressing NVM Programming Challenges</div>
              <p> Nascent persistent memory (PM) technologies promise the performance of DRAM with the durability of disk, but how best to integrate them into programming systems remains an open question. Recent work extends language memory models with a persistency model prescribing semantics for updates to PM. These semantics enable programmers to design data structures in PM that are accessed like memory and yet are recoverable upon crash or failure. Alas, we find the semantics and performance of existing approaches unsatisfying. Existing approaches require high-overhead mechanisms, are restricted to certain synchronization constructs, provide incomplete semantics, and/or may recover to state that cannot arise in fault-free execution. 

              We propose persistency semantics that guarantee failure atomicity of synchronization-free regions (SFRs) —program regions delimited by synchronization operations. Our approach provides clear semantics for the PM state recovery code may observe and extends C++11’s “sequential consistency for data-race-free” guarantee to post-failure recovery code. We investigate two designs for failure-atomic SFRs that vary in performance and the degree to which commit of persistent state may lag execution. We demonstrate both approaches in LLVM v3.6.0 and compare to a state-of-theart baseline to show performance improvement up to 87.5% (65.5% avg).</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">PLDI'18, June 2018</span>
          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/memsys17.pdf>Composing lifetime enhancing techniques for non-volatile main memories</a></h3>
            <div class="subheading mb-3">Addressing NVM Endurance Challenges</div>
              <p> Emerging byte-addressable non-volatile memory (NVM) technologies, such as PCM and ReRAM, offer significant gains in terms of density and power consumption over their volatile counterparts. Their write endurance is, however, orders of magnitude lower than DRAM, potentially causing devices to fail in seconds. Therefore, to use NVM as DRAM replacement, writes must be managed carefully.

              In this paper, we study the endurance problem for NVM main memories with realistic server workloads. We explore three existing techniques to extend NVM lifetime: last-level cache replacement policies, compression, and NVM wear-leveling. The first two approaches increase lifetime by reducing the write traffic from the cache to the main memory. Wear-leveling spreads writes and reduces hotspots responsible for fast failures.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">MEMSYS'17, October 2017</span>
          </div>
        </div>


        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/memsys15.pdf>Inefficiencies in the Cache Hierarchy: A Sensitivity Study of Cacheline Size with Mobile Workloads</a></h3>
            <div class="subheading mb-3">Pushing Mobile Performance and Efficiency Boundary</div>
              <p> With the rising number of cores in mobile devices, the cache hierarchy in mobile application processors gets deeper, and the cache size gets bigger. However, the cacheline size remained relatively constant over the last decade in mobile application processors. In this work, we investigate whether the cacheline size in mobile application processors is due for a refresh, by looking at inefficiencies in the cache hierarchy which tend to be exacerbated when increasing the cacheline size: false sharing and cacheline utilization.

              Firstly, we look at false sharing, which is more likely to arise at larger cacheline sizes and can severely impact performance. False sharing occurs when non-shared data structures, mapped onto the same cacheline, are being accessed by threads running on different cores, causing avoidable invalidations and subsequent misses. False sharing has been found in various places such as scientific workloads and real applications. We find that whilst increasing the cacheline size does increase false sharing, it still is negligible when compared to known cases of false sharing in scientific workloads, due to the limited level of thread-level parallelism in mobile workloads.

              Secondly, we look at cacheline utilization which measures the number of bytes in a cacheline actually used by the processor. This effect has been investigated under various names for a multitude of server and desktop applications. As a low cacheline utilization implies that very little of the fetched cachelines was used by the processor, this causes waste in bandwidth and energy in moving data across the memory hierarchy. The energy cost associated with data movements is much higher compared to logic operations, increasing the need for cache efficiency, especially in the case of an energy-constrained platform like a mobile device. We find that the cacheline utilization of mobile workloads is low in general, decreasing when increasing the cacheline size. When increasing the cacheline size from 64 bytes to 128 bytes, the number of misses will be reduced by 10%--30%, depending on the workload. However, because of the low cacheline utilization, this more than doubles the amount of unused traffic to the L1 caches.

              Using the cacheline utilization as a metric in this way, illustrates an important point. If a change in cacheline size would only be assessed on its local effects, we find that this change in cacheline size will only have advantages as the miss rate decreases. However, at system level, this change will increase the stress on the bus and increase the amount of wasted energy due to unused traffic. Using cacheline utilization as a metric underscores the need for system-level research when changing characteristics of the cache hierarchy.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">MEMSYS'15, October 2015</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=pdf/iiswc13.pdf>A structured approach to the simulation, analysis and characterization of smartphone applications</a></h3>
            <div class="subheading mb-3">Pushing Mobile Performance and Efficiency Boundary</div>
              <p> Full-system simulators are invaluable tools for designing new architectures due to their ability to simulate full applications as well as capture operating system behavior, virtual machine or hypervisor behavior, and interference between concurrently-running applications. However, the systems under investigation and applications under test have become increasingly complicated leading to prohibitively long simulation times for a single experiment. This problem is compounded when many permutations of system design parameters and workloads are tested to investigate system sensitivities and full-system effects with confidence. In this paper, we propose a methodology to tractably explore the processor design space and to characterize applications in a full-system simulation environment. We combine SimPoint, Principal Component Analysis and Fractional Factorial experimental designs to substantially reduce the simulation effort needed to characterize and analyze workloads. We also present a non-invasive user-interface automation tool to allow us to study all types of workloads in a simulation environment. While our methodology is generally applicable to many simulators and workloads, we demonstrate the application of our proposed flow on smartphone applications running on the Android operating system within the gem5 simulation environment.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">IISWC'13, September 2013</span>
          </div>
        </div>

      </div>

    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Selected Patents</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Instruction ordering</h3>
            <div class="subheading mb-3">Processor Architecture, US16/296,507</div>
              <p> A data processing apparatus includes obtain circuitry that obtains a stream of instructions. The stream of instructions includes a barrier creation instruction and a barrier inhibition instruction. Track circuitry orders sending each instruction in the stream of instructions to processing circuitry based on one or more dependencies. The track circuitry is responsive to the barrier creation instruction to cause the one or more dependencies to include one or more barrier dependencies in which pre-barrier instructions, occurring before the barrier creation instruction in the stream, are sent before post-barrier instructions, occurring after the barrier creation instruction in the stream, are sent. The track circuitry is also responsive to the barrier inhibition instruction to relax the barrier dependencies to permit post-inhibition instructions, occurring after the barrier inhibition instruction in the stream, to be sent before the prebarrier instructions.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">March 2019</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Method and apparatus for implementing lock-free data structures</h3>
            <div class="subheading mb-3"> Processor Architecture, US16/183,201</div>
              <p> An instruction set architecture of a data processing system includes one or more persistent atomic instructions that provide failure-safe atomicity. When issued, a sequence of operations associated with the persistent atomic instruction are performed and first data, associated with a first address in a persistent memory of the data processing system, is written to a point of persistence in the data processing system.  Access to data associated with the first address is controlled such that the first data is not available to other execution threads of the data processing system until completion of writing the first data to the point of persistence.  The point of persistence may be the persistent memory itself or a persist buffer.  The persist buffer may be a volatile or non-volatile buffer.  One or more monitors may control access to data at memory addresses dependent upon a designated state of exclusivity.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">November 2018</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patents.justia.com/patent/10445238>Robust Transactional Memory</a></h3>
            <div class="subheading mb-3">Processor Microarchitecture, US 10,445,238 </div>
            <p>Methods and apparatus are provided for executing a transaction in a data processing system,  Responsive to each memory access of the transaction, a transaction log is updated in a persistent memory.  After execution of the transaction and when the transaction log is complete, the transaction log is marked as ‘pending’.  When all values modified in the transaction have been written back to the persistent memory, the transaction log is marked as ‘free’.  When, following a reboot, a transaction log is marked as ‘pending’, data stored in the transaction log is copied to the persistent memory at addresses indicated in the transaction log.  After the copying is complete, the transaction log is marked as ‘free’.  Cache values modified in the transaction may be written back to persistent memory when evicted, and values read in the transaction may be read from the cache rather than from the transaction log.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">April 2018</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/cf/59/cf/eaebb28fc30280/US20190294364A1.pdf>Energy conservation for memory applications</a></h3>
            <div class="subheading mb-3">Memory System, US15/927,478</div>
            <p> Various implementations described herein refer to system memory cache that conserves energy by determining various instances where retaining data may be deemed unnecessary and/or skipping refresh of memory components in the cache that no longer need refreshing.  Some implementations described herein are related to on-chip or off-chip dynamic random access memory (DRAM) cache memory arrays.  For DRAM caches, such as on-chip DRAM caches (e.g., eDRAM, system cache) or off-chip DRAM caches (e.g., NVDIMM, hybrid memories), if a cache line (e.g., having a page size of 4KB) holds invalid data, refresh operations may be skipped.  NVDIMM refers to a non-volatile dual in-line memory module that is a type of random access memory.  In this instance, DRAM rows that map to invalid cache lines may be skipped for refresh.  Therefore, system cache memory may refer to a DRAM cache that needs less refresh instances, and in particular, the system cache memory may refer to a DRAM cache that does not refresh cache lines that are no longer valid, such as invalid cache lines.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">March 2018</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/49/a9/47/9402340dca683e/US20190155750A1.pdf>Multi-tier cache placement mechanism</a></h3>
            <div class="subheading mb-3">Processor Microarchitecture, PCT/GB2018/053361</div>
            <p>Storage of data in a cache system is controlled by a cache monitor. A cache line is filled in response to a memory instruction from a cache client. The cache monitor includes a predictor table and update logic. An entry in the predictor table comprises an instruction identifier that associates the entry with a memory instruction and, for each cache in the system, a reuse counter. The update logic is configured to update a reuse counter table dependent upon cache behavior in response to memory instructions. Storage of data a first data address in cache in response to a memory instruction having a first instruction identifier, is dependent upon reuse counter values in an entry of the predictor table associated with first instruction identifier. Reuse counters are updated dependent upon cache behavior. A Bloom filter or other data structure may be used to associate data addresses with a memory instruction.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">November 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/02/39/86/c9aba000861b1e/US20190129633A1.pdf>Initialisation of a storage device</a></h3>
            <div class="subheading mb-3">Memory System, GB2561011A</div>
            <p>A system comprising: a storage device having a storage portion 205 comprising a plurality of bit cells (0-2n-1)th coupled to respective first and second signal lines and control logic 203, 204 to alter a memory state of the plurality of bitcells via the first (wordlines WL(0)) signal lines and second (bitlines BL(0)) signal lines; a memory controller (8 figure 1) coupled to the storage device 10 to transmit one or more initialisation signals (e.g initialise signal, address (start), range (offset) and data) to the storage device to initialize (put in set or reset state) the storage portion over a clock cycle in response to the initialization signal(s), (figure 4b). The initialise select (IS) signal may be generated based on the initialisation signals and provide input to OR-gate 210, AND-gate logic (310 figure 4d) in conjunction with the first (wordline) signals (IWL(0-m)) to activate the initialisation of the respective bitcells. The storage element in the memory array bit cell may be a correlated electron switch (memory) (CES/CEM/CeRAM). The control logic may apply a first signal to produce a low first impedance state and a second signal to produce a second high impedance state. An embodiment also describes one or more buffers to receive access requests from a bus mater, and an arbiter to determine the order of access requests executed and a signal interface to generate hardware initialisation signals (address, range and data) which enable initialisation of the memory device.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">October 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/33/6a/77/c0dc742c81b3fa/US20190004960A1.pdf>Apparatus and method of handling caching of persistent data</a></h3>
            <div class="subheading mb-3">Memory System, US16/005,934</div>
            <p>An apparatus and method are provided for handling caching of persistent data. The apparatus comprises cache storage having a plurality of entries to cache data items associated with memory address in a non-volatile memory. The data items may comprise persistent data items and non-persistent data items. Write back control circuitry is used to control write back of the data items from the cache storage to the on-volatile memory. In addition, cache usage determination circuity is used to determine, in dependence on information indicative of capacity of a backup energy source, a subset of the plurality of entries to be used to store persistent data items. In response to an event causing the backup energy source to be used, the write back control circuitry is then arranged to initiate write back to the non-volatile memory of the persistent data items cached in the subset of the plurality of entries. By constraining the extent to which the cache storage is allowed to store persistent data items, taking into account the capacity of the backup energy source, the persistence of those data items can then be guaranteed in the event of the backup energy source being triggered, for example due to removal of the primary energy source for the apparatus.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">June 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/10/6d/10/77639d3045d654/GB2561011A.pdf>Initialisation of a storage device</a></h3>
            <div class="subheading mb-3">Memory System, PCT/GB2018/052997</div>
            <p>The present techniques generally relate to devices, method and/or systems for responding to a request for accessing a portion of a memory prior to completion of a requested operation to place the portion of the memory in an initialized state. In one example implementation, a memory controller may delay initiation of a write operation addressed to a particular portion of the memory until completion of a pending request to initialize the particular portion of the memory. In another example implementation, a memory controller may return values to service a request for a read operation comprising values representing an initialized state without accessing the particular portion of the memory responsive to a presence of a pending request to initialize the particular portion of the memory.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">March 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/df/65/8b/4420553d6ea232/US20180286475A1.pdf>Control of refresh operation for memory regions</a></h3>
            <div class="subheading mb-3">Memory System, US15/886,970</div>
            <p>An apparatus comprises first and second memory regions each to store data using a data storage technology for which retention of data for longer than a predetermined period of time is dependent on a refresh operation for refreshing data in the memory region being performed at a frequency that is greater than or equal to a minimum refresh frequency. The apparatus further comprises at least one controller to control storage of data in the first memory region with the refresh operation performed at a first frequency lower than said minimum refresh frequency when valid data is stored in the first memory region, and to control storage of data in the second memory region with the refresh operation performed at a second frequency that is greater than or equal to said minimum refresh frequency. The at least one controller is configured to communicate with the first memory region via a first memory channel and with the second memory region via a second memory channel.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">March 2017</span>
          </div>
        </div>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0"><a href=https://patentimages.storage.googleapis.com/76/4b/90/24b81eb638969d/US20170147207A1.pdf>Non-volatile buffer for memory operations</a></h3>
            <div class="subheading mb-3">Processor Microarchitecture, Memory System, US20170147207A1</div>
            <p>Subject matter disclosed herein may relate to buffers, and may relate more particularly to non-volatile buffers for memory operations.</p>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">November 2015</span>
          </div>
        </div>


      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="skills">
      <div class="w-100">
        <h2 class="mb-5">Talks</h2>

        <div class="subheading mb-3"></div>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-check"></i>
            <a href="pdf/spaa19_talk.pdf">SPAA'19 Talk: "Persistent Atomics for Implementing Durable Lock-free Data Structures for Non-Volatile Memory" </a>
            </li>
          <li>
            <i class="fa-li fa fa-check"></i>
            <a href="pdf/spaa19_paper.pdf">SPAA'19 Paper: "Persistent Atomics for Implementing Durable Lock-free Data Structures for Non-Volatile Memory"</a>
          </li>
          <li>
            <i class="fa-li fa fa-check"></i>
            <a href="pdf/memsys18_talk.pdf">MEMSYS'18 Talk: "Quantifying the performance overheads of PMDK" </a>
          </li>
          <li>
            <i class="fa-li fa fa-check"></i>
            <a href="pdf/memsys18_paper.pdf">MEMSYS'18 Paper: "Quantifying the performance overheads of PMDK"</a>
          </li>
        </ul>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="interests">
      <div class="w-100">
        <h2 class="mb-5">Research Interests</h2>
        <p>Apart from systems research related to non-volatile memory, I'm also interested in novel use cases of emerging non-volatile memories, ranging from off-chip to on-chip memory use cases, and from uses as memory to uses as analog computing device for machine learning and bioinformatics.</p>
        <p class="mb-3">Outside of memory, I'm also interested in exploring pushing up the boundary between hardware and software from ISA, i.e., EDGE, as non-volatile memory shifts the volatile and non-volatile boundary up from memory/storage to CPU caches/memory.

        In the past, I've also led the project on accelerating genomics on Arm, you can find the invited talk that I gave at Cambridge University Computer Laboratory on <a href="pdf/mimoics17_talk.pdf">Genomics at Arm</a>, also a short abstract on <a href="pdf/accelerator_abstract.pdf">Hardware Accelerators for Genomic Data Processing</a>.</p>
        <p class="mb-1">Please <a href="mailto:camwwang@gmail.com">get in touch</a> if you are interested in exploring collaboration opportunities.</p>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">
      <div class="w-100">
        <h2 class="mb-5">Services &amp; Awards</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            <a href=https://www.hpca-conf.org/2020/program-committee>Program Committee for HPCA 2020</a> </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            <a href=http://gem5.org/ASPLOS2017_tutorial>Organizer of Architectural Exploration with Gem5 Tutorial at ASPLOS 2017</a></li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Reviewer for ACM Transactions on Architecture and Code Optimization (TACO) 2018-19</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Program Committee and Session Chair for Arm Research Summit 2016-19 </li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            <a href=https://akolli.github.io/pubs/lsmp-toppicks19.pdf>IEEE Micro Top Picks 2019</a></li>
        </ul>
      </div>
    </section>

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
